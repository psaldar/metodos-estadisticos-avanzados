---
title: "Trabajo Final - Métodos Estadísticos Avanzados en Ciencia de los Datos"
author: "Pablo Saldarriaga-Aristizabal, Nicolás Prieto-Escobar, Obed Rios-Ruiz"
date: "Semestre 2020-1"
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
library(readxl)
library(ggplot2)
library(kableExtra)
library(matrixStats)
library(Hmisc)
library(pastecs)
library(corrplot)
library(mvtnorm)
library(ggplot2)
library(dplyr)
library(lme4)
library(car)
library(glmmLasso)
library(influence.ME)
```


## Introduccion

La intro

## Clasificación Industrial Seleccionada

La cementera

## Consolidación de Información

```{r}
all_data = read.csv("PreparacionDatos/Datos_completos.csv", encoding="UTF-8")
NIT = all_data['NIT'] 
data = all_data[,-c(1,2)]
```


## Transformación  de Variables y Análisis Descriptivo


Damos una visualizacion inicial al conjunto de datos con el que se va a trabajar:

```{r}
kable(head(round(data,2)))
```

En la siguiente tabla, vemos información descriptiva de las variables que se considerarán en la etapa de modelamiento del trabajo, vemos así que contamos con un total de 11 variables, cada una con magnitudes diferentes. Vemos que algunos indicadores tienen valores entre 0 y 1 tal como lo es el desempleo, mientras que otras variables representan dinero, tal como la trm, el monto de gastos y ventas. Así, tenemos una idea inicial de las características del conjunto de datos, por lo que se aplicarán lo métodos correspondientes cuando sea necesario, si lo que se realizará es sensible a la escala de los datos.

```{r}
summary_df <- stat.desc(data)
kable(summary_df)
```
Además de la información descriptiva presentados en la tabla anterior, podemos ver para cada una de las variables, su distribución de forma visual con la ayuda de la creación de histogramas de frecuencia.

```{r}
hist(data)
```


Vamos a obtener la informacion relacionada a las medidas de centralidad y dispersion del conjunto de datos. Inicialmente, presentamos información del vector de medias y medianas que describen la centralidad del conjutno de datos. Posteriormente, consideramos las matrices de Covarianza y Correlación para tener una intuición de la variabilidad de la información que consideramos.

#### Vector de Medias
```{r}
mean_data = colMeans(data)
kable(formatC(mean_data,format = "e", digits = 2))
```

### Vector de Medianas
```{r}
median_data = colMedians(as.matrix(data))
names(median_data) = names(data)
kable(formatC(median_data,,format = "e", digits = 2))
```

### Boxplot

```{r}
par(mfrow=c(1,2))
bxplot_costos = boxplot(Costo.de.ventas~Year, data = all_data)
bxplot_gastos = boxplot(Gastos.de.ventas~Year, data = all_data)
```

```{r}
### Outliers para costos
kable(all_data[(all_data$Costo.de.ventas %in% bxplot_costos$out),]$NIT)
```

```{r}
### Outliers para gastos
kable(all_data[(all_data$Gastos.de.ventas %in% bxplot_gastos$out),]$NIT)
```

```{r}
par(mfrow=c(1,2))
bxplot_costos_dif = boxplot(Costo.de.ventas_dif~Year, data = all_data)
bxplot_gastos_dif = boxplot(Gastos.de.ventas_dif~Year, data = all_data)
```

```{r}
### Outliers para costos dif
kable(all_data[(all_data$Costo.de.ventas_dif %in% bxplot_costos_dif$out),]$NIT)
kable(all_data[(all_data$Costo.de.ventas_dif %in% bxplot_costos_dif$out),]$Costo.de.ventas_dif)
```

```{r}
### Outliers para gastos dif
kable(all_data[(all_data$Gastos.de.ventas_dif %in% bxplot_gastos_dif$out),]$NIT)
kable(all_data[(all_data$Gastos.de.ventas_dif %in% bxplot_gastos_dif$out),]$Year)
kable(all_data[(all_data$Gastos.de.ventas_dif %in% bxplot_gastos_dif$out),]$Gastos.de.ventas_dif)
```

#### Analisis:


Al observar la distribución del comportamiento de las variables de ventas y gastos para los 3 años en consideración, podemos ver que no hay mucha variación entre el comportamiento de estas a lo largo del tiempo, vemos que en particular, tanto el monto de costo y gasto promedio (mediana) es constante para los 3 años, aunque se nota un aumento en los costos en el año 2018 para el caso de algunas empresas. Ademas, vemos para que caso de los Costos, las mismas 2 empresas (relacionadas a los NITs 860009694 y 900378893) fueron las que presentaron un maypr valor de costos en los 3 periodos, por lo que el boxplot los considera registros outliers. Mirando la distribución de los gatos, notamos que una empresa tuvo los gastos mas altos en los 3 periodos (relacionadas al NIT 801002644) pero adicional, en el último año, la empresa con el NIT 800015615 tuvo un aumento en sus gastos, por lo que es considerado también como un outlier por el boxplot.

Pasando a la distribución de las variables de diferencia de costos y gastos, vemos para ambos casos los registros outliers son aquellos que tienen un valor negativo en su diferencia. Podemos ver que para el caso del 2016 en la variable costos, las empresas outliers fueron las correspondiente a los NITs 801002644, 806014553, 890909034, 900378893, 900437650, de estas, la única que no presenta una diferencia negativa fue la primera (801002644), por lo que puede indicar un aumento considerable (raro) en el mercado en término de los costos de venta, mientras que todas las otras empresas presentaron una disminución considerable en este mismo concepto. Para el caso del 2017, solo una empresa fue considerada como outlier (801002644), la cual apareció en el 2016 y en este caso, tenemos que sus costos de venta aumentaron del 2016 al 2017, lo que también indica, que el comportamiento del cambio de los costos para el 2017, fueron "normales" para las demás empresas. Mirando el comportamiento en el 2018, encontramos a las empresas 806014553, 860009694, 890300012, lo cual nos indica que nuevamente la empresa que tuvo aumentos considerables en los últimmos años (860009694), también los tuvo en el 2018, ahora acompañado de otra empresa (806014553), la cual también tuvo un aumento considerable en los costos en comparación de las demás empresas. Ahora bien, aparece una empresa que tuvo una baja considerable (fuera de lo normal) en dicho concepto, lo cual la hace aparecer como un registro outlier (890300012).

Ahora mirando la variable de diferencia de gastos, solamente 3 empresas tienen comportamientos grandes en estas diferencias, asi la empresa 806014553 es la que reporta un cambio grande (negativo) en sus gastos, lo que indica que los gastos de venta fueron mucho menores en el 2016 a comparación del 2015, mientras que las empresas con NIT 801002644, 890904459 reportan un aumento en esta diferencia. En particular vemos que aparece la empresa 801002644, la cual vimos que tuvo un aumento en sus costos durante los 3 periodos analizados, y ahora presenta un aumento de gatos. Para el año 2017, se tuvo un aumento en la cantidad de empresas que variaron considerablemente sus gastos de ventas, asi tenemos que las empresas con los NITs 800015615, 801002644, 805012368 fueron las que presentaron un incremento (Note nuevamente la empresa 801002644), mientras que 4 presentaron una disminución en sus gastos (empresas con los NITs 806014553, 830037495, 860050956, 890311366, 900378893). Por último, para el año 2018, tenemos 3 empresas con estos cambios atipicos en sus gastos de venta, tenemos asi que las empresas con NITs 800236890, 806014553 son las que presentaron un incremento en dicha variable, mientras que la empresa 890311366 fue la única que presentó una disminusión considerable en sus gastos. Adicional a esto, vemos que la empresa que tiempre aumentó sus costos además de sus gastos en los últimos años, para el 2018 tuvo un cambio "normal" en sus gastos en comparación a las demás empresas.




#### Matriz de Covarianzas
```{r}
cov_data = cov(data)
kable(formatC(cov_data,format = "e", digits = 2))
```

#### Matriz de Correlación
```{r}
cor_data = cor(data)
kable(round(cor_data,2))
```

```{r}
corrplot(cor_data, method="circle")
```

Dado que en este trabajo se pretende realizar la modelación de las variables de costo y gasto de ventas, la matriz de correlación es un buen indicador para observar relaciones lineales existentes en las variables. En particular, vemos para el caso de la información de gastos, una "fuerte" correlación de las variables de costo, diferencia de costos y diferencia de ventas. Para este caso, es natural encontrar una correlacion positiva con dichas variables, pues es claro que costos y gastos están asociados entre sí. Igualmente, la variable de diferencia de gastos, fue calculada con la variable gastos, por lo tanto tiene sentido encontrar esta correlación. Por otro lado, tanto para la variable de ventas como gastos, no se ven correlaciones fuertes en relación a las variables macro-económicas, lo que nos indica que no existe una relación lineal entre esta variable y las demás. Por lo que una buena alternativa en este trabajo, será considerar transformaciones no lineales de las variables para encontrar una dependencia con la información de los costos de venta.

## Visualizacion de la distribucion de los datos


```{r}
panel.cor <- function(x, y, digits = 2, prefix = "", cex.cor, ...)
{
    usr <- par("usr"); on.exit(par(usr))
    par(usr = c(0, 1, 0, 1))
    r <- abs(cor(x, y))
    txt <- format(c(r, 0.123456789), digits = digits)[1]
    txt <- paste0(prefix, txt)
    if(missing(cex.cor)) cex.cor <- 0.8/strwidth(txt)
    text(0.5, 0.5, txt, cex = cex.cor * r)
}

panel.hist <- function(x, ...)
{
    usr <- par("usr"); on.exit(par(usr))
    par(usr = c(usr[1:2], 0, 1.5) )
    h <- hist(x, plot = FALSE)
    breaks <- h$breaks; nB <- length(breaks)
    y <- h$counts; y <- y/max(y)
    rect(breaks[-nB], 0, breaks[-1], y, col = "black", ...)
}
```

```{r}
pairs(data,diag.panel = panel.hist, lower.panel = panel.cor)
```

### Visualizacion de los datos segun curvas de normalidad

```{r}
### Funcion para encontrar los contornos
c_alpha = function(alpha, sigma, p){
  res = (2*pi)^(-p/2)*(det(sigma))^(-1/2)*exp(-1/2*qchisq(1-alpha, df = p))
  
  return(res)
}

grafica = function(data, name1, name2){

  data_aux = data[c(name1,name2)]
  names(data_aux) = c("y1","y2")
  
  cov_data = cov(data_aux)
  mean_data = mean=colMeans(data_aux)
  
  min_value1 = min(data[name1])
  max_value1 = max(data[name1])
  
  min_value2 = min(data[name2])
  max_value2 = max(data[name2])
  
  n = 100
  
  y1 = seq(min_value1, max_value1, length.out = n)
  y2 = seq(min_value2, max_value2, length.out = n)
  
  grid = expand.grid(y1,y2)
  grid$Z<-apply(grid,1,dmvnorm,mean = mean_data,sigma=cov_data)
  Z<-matrix(grid$Z,nrow=n,ncol=n)
  
  contornos = sapply(c(0.01, 0.05, 0.1), c_alpha, sigma = cov_data, 2)
  
  contour(y1,y2,Z,levels=contornos,labels=c("99%","95%","90%"),
          las=1)
  points(data_aux$y1,data_aux$y2)
  grid()  
  title(main = "Contornos de distribucion normal", xlab = name1, ylab = name2)
}
```

```{r}
p1 = grafica(data, "TRM", "PIB")
```

```{r}
p2 = grafica(data, "Costo.de.ventas" , "Costo.de.ventas_dif")
```

```{r}
p3 = grafica(data, "Costo.de.ventas" , "Gastos.de.ventas")
```

### Creacion de modelos

```{r}
data_aux = select(all_data,select = -starts_with('NIT'))

empresas_train = c(800015615, 800045720,
                   800081030, 800112440,
                   800118660, 800157469,
                   800232356, 800236890,
                   801002644, 805012368,
                   830030574, 860009694,
                   860030360, 860050956,
                   890117431, 890311366,
                   890904459, 900173460,
                   900184722, 900234565,
                   900364670, 900389088)

empresas_test = c(806014553, 830037495,
                   830052054, 860033653,
                   860501682, 890300012,
                   890909034, 890929951,
                   900204182, 900378893,
                   900437650)

train = all_data$NIT%in%empresas_train
test = all_data$NIT%in%empresas_test

NIT_train = NIT[train,]
NIT_test = NIT[test,]

data_train = data_aux[train,]
rownames(data_train) <- NULL
data_train_z = scale(data_train, center = TRUE, scale = TRUE)

media_tr = attr(data_train_z, 'scaled:center')
stdev_tr = attr(data_train_z, 'scaled:scale')

data_train_z = as.data.frame(data_train_z)

data_test = data_aux[test,]
rownames(data_test) <- NULL
data_test_z = as.data.frame(scale(data_test,  center = media_tr, scale = stdev_tr))

data_train_z$NIT = NIT_train
data_test_z$NIT = NIT_test

```

## Modelo para los Costos

### Modelo Lineal General

```{r}
mod_lin = lm('Costo.de.ventas_dif~PIB+TRM+Desempleo+Inflacion+Tasa_Intervencion+Balance_CC+Balance_Fiscal', data = data_train_z)
```

```{r}
summary(mod_lin)
```
#### Desempeno del Modelo Entrenado

En el conjunto de entrenamiento:
```{r}
preds = predict(mod_lin)

plot(preds, data_train_z$Costo.de.ventas_dif, xlab = 'Valor predicho', ylab = 'Valor Real')
abline(a=0, b=1, lwd = 2, col = 'red')
```

En el conjunto de Prueba
```{r}
preds_test = predict(mod_lin, newdata = data_test_z)
plot(preds_test, data_test_z$Costo.de.ventas_dif, xlab = 'Valor predicho', ylab = 'Valor Real')
abline(a=0, b=1, lwd = 2, col = 'red')
```

### Graficos de Evaluacion de modelos

```{r}
par(mfrow=c(3,2))
mod_plot = plot(mod_lin, which = c(1:6))
```
### REVISAR ESTE ANALISIS
De los gráficos anteriores, en particular analizando el valor de la distancia de Cook para las observaciones, notamos que las observaciones 9, 31, 58 son candidatas a ser registros atípicos en el conjunto de datos, por lo que entrenaremos un nuevo modelo eliminando estos registros. Notar que el tercer registro coincide con la empresa de NIT 860009694 para elaño 2018, lo cual coincide con uno de los registros raros encontrados en la sección descriptiva utilizando el boxplot.

```{r}
### Vector para eliminar registros atipicos
outliers = c(9, 31, 58)
data_train_z_noOut = data_train_z[-outliers,]
```



```{r}
h_ii<-hatvalues(mod_lin)
plot(hatvalues(mod_lin),las=1,xlab="i",ylab="hii",main="Influencia (h_ii)",type="h")
```

### Inflacion de la varianza

```{r}
#vif(mod_lin)
```

## Entrenamiento del modelo sin Outliers

```{r}
mod_lin02 = lm('Costo.de.ventas_dif~PIB+TRM+Desempleo+Inflacion+Tasa_Intervencion+Balance_CC+Balance_Fiscal', data = data_train_z_noOut)
```

```{r}
summary(mod_lin02)
```


#### Desempeno del Modelo Entrenado sin Outliers

En el conjunto de entrenamiento:
```{r}
preds = predict(mod_lin02)

plot(preds, data_train_z_noOut$Costo.de.ventas_dif, xlab = 'Valor predicho', ylab = 'Valor Real')
abline(a=0, b=1, lwd = 2, col = 'red')
```

En el conjunto de Prueba
```{r}
preds_test = predict(mod_lin02, newdata = data_test_z)
plot(preds_test, data_test_z$Costo.de.ventas_dif, xlab = 'Valor predicho', ylab = 'Valor Real')
abline(a=0, b=1, lwd = 2, col = 'red')
```

### Graficos de Evaluacion de modelos entrenando sin Outliers

```{r}
par(mfrow=c(3,2))
mod_plot = plot(mod_lin02, which = c(1:6))
```


### Modelo Lineal con Regularizacion

Vamos a encontrar el parametri de regulairzacion
```{r}
library(glmnet)

f1 = formula('Costo.de.ventas_dif~-1+PIB+TRM+Desempleo+Inflacion+Tasa_Intervencion+Balance_CC+Balance_Fiscal')


X = model.matrix(f1, data = as.data.frame(data_train_z))
Y = data_train_z$Costo.de.ventas

lambda_grid = 10^seq(1,-2,length.out = 100)
modelo_regularizacion = cv.glmnet(x = X, y = Y, lambda = lambda_grid)
```

```{r}
plot(modelo_regularizacion)
```

Entrenamos el modelo agregando el parametro de regularizacion, y asi ver relevancia de variables
```{r}
mod_lin_reg = glmnet(x = X, y = Y, lambda = modelo_regularizacion$lambda.min, alpha = 1, intercept = FALSE)
coef(mod_lin_reg)
```


### Modelo de Efectos Mixtos

```{r}

#mod_me = lmer('Costo.de.ventas_dif~Gastos_de_ventas+(Gastos_de_ventas|NIT)', data = data_train_z)
mod_me = lmer('Costo.de.ventas_dif~PIB+(PIB|NIT)', data = data_train_z)
```

```{r}
par(mfrow=c(3,2))
plot(mod_me, which = c(1:6))
```

```{r}
preds = predict(mod_me)
plot(preds,data_train_z$Costo.de.ventas_dif)
abline(a=0, b=1, lwd = 2, col = 'red')
```

```{r}
preds = predict(mod_me, newdata = data_test_z,allow.new.levels=TRUE)
plot(preds,data_test_z$Costo.de.ventas_dif)
abline(a=0, b=1, lwd = 2, col = 'red')
```


```{r}
## Generalized linear model Lasso
#glm_obj <- glmmLasso(Costo.de.ventas~TRM+PIB+Balance_CC+Desempleo+Balance_Fiscal, rnd = list(NIT=~1+PIB), data = data_train_z, lambda=0.9, family = gaussian(link ="identity"))
#summary(glm_obj)
```


```{r}
#preds = predict(glm_obj, data = data_train_z)
#plot(preds,data_train_z$Costo_de_ventas)
#abline(a=0, b=1, lwd = 2, col = 'red')
```


```{r}
infl <- influence(mod_me, obs = TRUE)
cooks.distance(infl)
plot(infl, which = "cook")

```


```{r}
plot(all_data$Year, all_data$Costo.de.ventas, col=all_data$NIT, xlab = "Año", ylab = "Valor del Costo de Venta por Empresa")
```








