---
title: "Trabajo Final - Métodos Estadísticos Avanzados en Ciencia de los Datos"
author: "Pablo Saldarriaga-Aristizabal, Nicolás Prieto-Escobar, Obed Rios-Ruiz"
date: "Semestre 2020-1"
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
library(readxl)
library(ggplot2)
library(kableExtra)
library(matrixStats)
library(Hmisc)
library(pastecs)
library(corrplot)
library(mvtnorm)
library(ggplot2)
library(dplyr)
library(lme4)
library(car)
library(glmmLasso)
library(influence.ME)
```


## Introduccion

El modelamiento del comportamiento de diferentes variables es un tema que ha sido estudiado en sectores energéticos, industriales, económicos y financieros. De allí se comienza a apreciar tanto la importancia que tienen los datos hoy en día al igual que las técnicas utilizadas para su modelamiento. La estadística es una disciplina que se preocupa por la recolección, organización, interpretación y análisis de datos, que, según su aplicación puede traer un gran impacto en la industria al momento de la toma de decisiones. En particular, diferentes técnicas estadísticas han sido utilizadas en el sector financiero, las cuales permiten modelar comportamiento de los clientes, acciones, entre otras variables.

Diferentes industrias dentro de su funcionamiento, deben presentar ante la superintendencia información relacionando los gastos y ventas que presentaron anualmente. Además, se presume que del mercado colombiano, como en los procesos de las industria está esa interacción con todo el mercado, es posible pensar que exista una relación entre las diferentes variables macroeconomicas (ej. PIB, TRM, Balance Fiscal, Indice de Desempleo, etc.) y estos montos de costos y gastos de las empresas. Debido a la cantidad de información con la que se cuenta (información de costos y gastos para diferentes empresas en colombia entre los años 2016 y 2018), se sabe que no se cuenta con información suficiente para la construcción de un modelo por empresa que permita ver la relación existente entre las variables macroeconómicas y las variables asociadas a costos y gastos de ventas. Por lo anterior, es posible considerar un conjunto de datos como la consolidación de la información de todas las empresas junto con la información macroeconomica para los años en estudio, así buscando construir un modelo general para realizar la modelación de estas variables reportadas ante la superintendencia para un conjunto de empresas cuya industria sea similar.

Por lo tanto, para el conjunto de datos meniconado anteriormente, se buscará modelar la información de costos y gastos de venta a partir de las variables macroeconomicas disponibles, al igual que analizar si al realizar alguna transformación a dichas variables resulta relevante al momento de la creación del modelo. Se utilizarán modelos lineales, comenzando con la evaluación del modelo lineal general, hasta la aplicación de modelos de efectos mixtos. Esta última estructura de modelos, es bastante usado al momento de tener individuos que comparten la misma información pero tienen una salida diferente (en nuestro caso, todas las empresas comparten la misma información de las variables macroeconómicas), por lo que utilizar este tipo de modelos resulta de gran interés ya que permite modelar tanto efectos a nivel de individuo como agregando un efecto aleatorio.

## Clasificación Industrial Seleccionada

El sector de la construcción es uno de los más relevantes en la economía colombiana. En nuestro contexto nacional el sector es considerado como uno de los más vitales para el desarrollo del país y representa uno de los más importantes rubros en materia de produccción interna componiendo cada año de 6 a 7 por ciento del producto interno bruto total y hasta un 7.1% del total de ocupados a nivel nacional. Dicho sector es caracterizado por sus fluctuaciones estacionarias fuertemente influenciadas por los planes de infraestructura de gran escala y los planes de gobierno. Respecto al último trimestre de 2019 tuvo un aumento de 3.4%, uno de los más altos a nivel de america latina.

Si bien las estimaciones globales para el año 2020 en Colombia para esta industria eran positivas, la coyuntura del COVID-19 ha de perturbar fuertemente el sector,  afectando con alto impacto a los importadores de materiales y a la demanada frente a los retrasos en la ejecución de obras. Desde enero el sector de la producción de concreto
ya estaba presentando caídas significativas de hasta un 8.3% respecto al año pasado en el mismo mes, por lo que se esperan peores resultados al cierre del segundo trimestre del año presente. Muchas compañías planearon incrementos en sus precios, con la esperanza de generar mayores ingresos, pero dichos planes han de ser postergados bajo la actual coyuntura. La demanda, el driver más relevante en la industria, claramente se ve desplazado efecto del impedimento de comercialización y la paralisis en el país bajo las medidas de cuarentena
nacional. Un punto importante es que algunas compañías del sector podrán seguir con sus actividades producto de la inclusión de actividades de infraestructura como vital durante la crisis del COVID-19.

Frente a la incertidumbre que generan estos escenarios y como la dinámica particular de cada compañía que aporta al crecimiento de la industria total evoluciona en el tiempo se torna relevante construir análisis y modelos estadísticos robustos que respondan a las perturbaciones en el mercado y permitan obtener información
valiosa para la toma de decisiones.

## Consolidación de Información

```{r}
all_data = read.csv("PreparacionDatos/Datos_completos.csv", encoding="UTF-8")
NIT = all_data['NIT'] 
data = all_data[,-c(1,2)]
```


## Transformación de Variables y Análisis Descriptivo


Damos una visualizacion inicial al conjunto de datos con el que se va a trabajar:

```{r}
kable(head(round(data,2))) %>%
  kable_styling(bootstrap_options = "striped", full_width = F, position = "center")%>%
  scroll_box("100%", height = "200px")
```

En la siguiente tabla, vemos información descriptiva de las variables que se considerarán en la etapa de modelamiento del trabajo, vemos así que contamos con un total de 11 variables, cada una con magnitudes diferentes. Vemos que algunos indicadores tienen valores entre 0 y 1 tal como lo es el desempleo, mientras que otras variables representan dinero, tal como la trm, el monto de gastos y ventas. Así, tenemos una idea inicial de las características del conjunto de datos, por lo que se aplicarán lo métodos correspondientes cuando sea necesario, si lo que se realizará es sensible a la escala de los datos.

```{r}
summary_df <- stat.desc(data)
kable(summary_df)
```
Además de la información descriptiva presentados en la tabla anterior, podemos ver para cada una de las variables, su distribución de forma visual con la ayuda de la creación de histogramas de frecuencia.

```{r}
hist(data)
```


Vamos a obtener la informacion relacionada a las medidas de centralidad y dispersion del conjunto de datos. Inicialmente, presentamos información del vector de medias y medianas que describen la centralidad del conjunto de datos. Posteriormente, consideramos las matrices de Covarianza y Correlación para tener una intuición de la variabilidad de la información que consideramos.

#### Vector de Medias
```{r}
mean_data = colMeans(data)
kable(formatC(mean_data,format = "e", digits = 2))
```

### Vector de Medianas
```{r}
median_data = colMedians(as.matrix(data))
names(median_data) = names(data)
kable(formatC(median_data,,format = "e", digits = 2))
```

### Boxplot

```{r}
par(mfrow=c(1,2))
bxplot_costos = boxplot(Costo.de.ventas~Year, data = all_data)
bxplot_gastos = boxplot(Gastos.de.ventas~Year, data = all_data)
```

```{r}
### Outliers para costos
kable(all_data[(all_data$Costo.de.ventas %in% bxplot_costos$out),]$NIT)
```

```{r}
### Outliers para gastos
kable(all_data[(all_data$Gastos.de.ventas %in% bxplot_gastos$out),]$NIT)
```

```{r}
par(mfrow=c(1,2))
bxplot_costos_dif = boxplot(Costo.de.ventas_dif~Year, data = all_data)
bxplot_gastos_dif = boxplot(Gastos.de.ventas_dif~Year, data = all_data)
```

```{r}
### Outliers para costos dif
kable(all_data[(all_data$Costo.de.ventas_dif %in% bxplot_costos_dif$out),]$NIT)
#kable(all_data[(all_data$Costo.de.ventas_dif %in% bxplot_costos_dif$out),]$Costo.de.ventas_dif)
```

```{r}
### Outliers para gastos dif
kable(all_data[(all_data$Gastos.de.ventas_dif %in% bxplot_gastos_dif$out),]$NIT)
#kable(all_data[(all_data$Gastos.de.ventas_dif %in% bxplot_gastos_dif$out),]$Year)
#kable(all_data[(all_data$Gastos.de.ventas_dif %in% bxplot_gastos_dif$out),]$Gastos.de.ventas_dif)
```

#### Análisis:


Al observar la distribución del comportamiento de las variables de ventas y gastos para los 3 años en consideración, podemos ver que no hay mucha variación entre el comportamiento de estas a lo largo del tiempo, vemos que en particular, tanto el monto de costo y gasto promedio (mediana) es constante para los 3 años, aunque se nota un aumento en los costos en el año 2018 para el caso de algunas empresas. Ademas, vemos para que caso de los Costos, las mismas 2 empresas (relacionadas a los NITs 860009694 y 900378893) fueron las que presentaron un maypr valor de costos en los 3 periodos, por lo que el boxplot los considera registros outliers. Mirando la distribución de los gatos, notamos que una empresa tuvo los gastos mas altos en los 3 periodos (relacionadas al NIT 801002644) pero adicional, en el último año, la empresa con el NIT 800015615 tuvo un aumento en sus gastos, por lo que es considerado también como un outlier por el boxplot.

Pasando a la distribución de las variables de diferencia de costos y gastos, vemos para ambos casos los registros outliers son aquellos que tienen un valor negativo en su diferencia. Podemos ver que para el caso del 2016 en la variable costos, las empresas outliers fueron las correspondiente a los NITs 801002644, 806014553, 890909034, 900378893, 900437650, de estas, la única que no presenta una diferencia negativa fue la primera (801002644), por lo que puede indicar un aumento considerable (raro) en el mercado en término de los costos de venta, mientras que todas las otras empresas presentaron una disminución considerable en este mismo concepto. Para el caso del 2017, solo una empresa fue considerada como outlier (801002644), la cual apareció en el 2016 y en este caso, tenemos que sus costos de venta aumentaron del 2016 al 2017, lo que también indica, que el comportamiento del cambio de los costos para el 2017, fueron "normales" para las demás empresas. Mirando el comportamiento en el 2018, encontramos a las empresas 806014553, 860009694, 890300012, lo cual nos indica que nuevamente la empresa que tuvo aumentos considerables en los últimmos años (860009694), también los tuvo en el 2018, ahora acompañado de otra empresa (806014553), la cual también tuvo un aumento considerable en los costos en comparación de las demás empresas. Ahora bien, aparece una empresa que tuvo una baja considerable (fuera de lo normal) en dicho concepto, lo cual la hace aparecer como un registro outlier (890300012).

Ahora mirando la variable de diferencia de gastos, solamente 3 empresas tienen comportamientos grandes en estas diferencias, asi la empresa 806014553 es la que reporta un cambio grande (negativo) en sus gastos, lo que indica que los gastos de venta fueron mucho menores en el 2016 a comparación del 2015, mientras que las empresas con NIT 801002644, 890904459 reportan un aumento en esta diferencia. En particular vemos que aparece la empresa 801002644, la cual vimos que tuvo un aumento en sus costos durante los 3 periodos analizados, y ahora presenta un aumento de gatos. Para el año 2017, se tuvo un aumento en la cantidad de empresas que variaron considerablemente sus gastos de ventas, asi tenemos que las empresas con los NITs 800015615, 801002644, 805012368 fueron las que presentaron un incremento (Note nuevamente la empresa 801002644), mientras que 4 presentaron una disminución en sus gastos (empresas con los NITs 806014553, 830037495, 860050956, 890311366, 900378893). Por último, para el año 2018, tenemos 3 empresas con estos cambios atipicos en sus gastos de venta, tenemos asi que las empresas con NITs 800236890, 806014553 son las que presentaron un incremento en dicha variable, mientras que la empresa 890311366 fue la única que presentó una disminusión considerable en sus gastos. Adicional a esto, vemos que la empresa que tiempre aumentó sus costos además de sus gastos en los últimos años, para el 2018 tuvo un cambio "normal" en sus gastos en comparación a las demás empresas.


Asi, estos cambios en las industrias en sus costos y gastos de ventas, pueden estar directamente relacionados con algunos eventos que hayan hecho la gran variación en la materia prima requerida para sus productos (tipos de mezlcas de cemento por ejemplo), además que el sector seleccionado depende bastante de los planes de infraestructura que se tengan, por lo que también es factible que en los periodos analizados, hayan ocurrido cambios en estos planes dentro de la contratación de cada empresa, y sean estas las causas que nos lleven a ver diferencias tan grandes de periodo a periodo (tanto positivas como negativas)

#### Matriz de Covarianzas
```{r}
cov_data = cov(data)
kable(formatC(cov_data,format = "e", digits = 2))
```

#### Matriz de Correlación
```{r}
cor_data = cor(data)
kable(round(cor_data,2))
```

```{r}
corrplot(cor_data, method="circle")
```

Dado que en este trabajo se pretende realizar la modelación de las variables de costo y gasto de ventas (también considerando la variante en las diferencias de las variables por periodo), la matriz de correlación es un buen indicador para observar relaciones lineales existentes en las variables. En particular, vemos para el caso de la información de gastos, una "fuerte" correlación de las variables de costo, diferencia de costos y diferencia de ventas. Para este caso, es natural encontrar una correlacion positiva con dichas variables, pues es claro que costos y gastos están asociados entre sí. Igualmente, la variable de diferencia de gastos, fue calculada con la variable gastos, por lo tanto tiene sentido encontrar esta correlación. Por otro lado, tanto para la variable de ventas como gastos, no se ven correlaciones fuertes en relación a las variables macro-económicas, lo que nos indica que no existe una relación lineal entre esta variable y las demás. Por lo que una buena alternativa en este trabajo, será considerar transformaciones no lineales de las variables para encontrar una dependencia con la información de los costos de venta. Ahora, mirando las variables de diferencia de gastos y costos, vemos que existen dependencias lineales mayores con las variables macroeconómicas a diferencia de las variables originales, así vemos que la diferencia en costos tiene un grado de asociación con todas las variables macroeconomicas, mientras que los gastos presenta una relación lineal con el balance de cuenta corriente, por lo que se podría pensar que existen relaciones no lineales respecto a los otros indicadores económicos.

## Visualizacion de la distribucion de los datos


```{r}
panel.cor <- function(x, y, digits = 2, prefix = "", cex.cor, ...)
{
    usr <- par("usr"); on.exit(par(usr))
    par(usr = c(0, 1, 0, 1))
    r <- abs(cor(x, y))
    txt <- format(c(r, 0.123456789), digits = digits)[1]
    txt <- paste0(prefix, txt)
    if(missing(cex.cor)) cex.cor <- 0.8/strwidth(txt)
    text(0.5, 0.5, txt, cex = cex.cor * r)
}

panel.hist <- function(x, ...)
{
    usr <- par("usr"); on.exit(par(usr))
    par(usr = c(usr[1:2], 0, 1.5) )
    h <- hist(x, plot = FALSE)
    breaks <- h$breaks; nB <- length(breaks)
    y <- h$counts; y <- y/max(y)
    rect(breaks[-nB], 0, breaks[-1], y, col = "black", ...)
}
```

```{r}
pairs(data,diag.panel = panel.hist, lower.panel = panel.cor)
```

### Visualizacion de los datos segun curvas de normalidad

```{r}
### Funcion para encontrar los contornos
c_alpha = function(alpha, sigma, p){
  res = (2*pi)^(-p/2)*(det(sigma))^(-1/2)*exp(-1/2*qchisq(1-alpha, df = p))
  
  return(res)
}

grafica = function(data, name1, name2){

  data_aux = data[c(name1,name2)]
  names(data_aux) = c("y1","y2")
  
  cov_data = cov(data_aux)
  mean_data = mean=colMeans(data_aux)
  
  min_value1 = min(data[name1])
  max_value1 = max(data[name1])
  
  min_value2 = min(data[name2])
  max_value2 = max(data[name2])
  
  n = 100
  
  y1 = seq(min_value1, max_value1, length.out = n)
  y2 = seq(min_value2, max_value2, length.out = n)
  
  grid = expand.grid(y1,y2)
  grid$Z<-apply(grid,1,dmvnorm,mean = mean_data,sigma=cov_data)
  Z<-matrix(grid$Z,nrow=n,ncol=n)
  
  contornos = sapply(c(0.01, 0.05, 0.1), c_alpha, sigma = cov_data, 2)
  
  contour(y1,y2,Z,levels=contornos,labels=c("99%","95%","90%"),
          las=1)
  points(data_aux$y1,data_aux$y2)
  grid()  
  title(main = "Contornos de distribucion normal", xlab = name1, ylab = name2)
}
```

```{r}
p1 = grafica(data, "TRM", "PIB")
```

```{r}
p2 = grafica(data, "Costo.de.ventas" , "Costo.de.ventas_dif")
```

```{r}
p3 = grafica(data, "Gastos.de.ventas" , "Gastos.de.ventas_dif")
```

### Creacion de modelos

```{r}
data_aux = select(all_data,select = -starts_with('NIT'))
data_aux = select(data_aux,select = -starts_with('Year'))

empresas_train = c(800015615, 800045720,
                   800081030, 800112440,
                   800118660, 800157469,
                   800232356, 800236890,
                   801002644, 805012368,
                   830030574, 860009694,
                   860030360, 860050956,
                   890117431, 890311366,
                   890904459, 900173460,
                   900184722, 900234565,
                   900364670, 900389088)

empresas_test = c(806014553, 830037495,
                   830052054, 860033653,
                   860501682, 890300012,
                   890909034, 890929951,
                   900204182, 900378893,
                   900437650)

train = all_data$NIT%in%empresas_train
test = all_data$NIT%in%empresas_test

NIT_train = NIT[train,]
NIT_test = NIT[test,]

data_train = data_aux[train,]
rownames(data_train) <- NULL
data_train_z = scale(data_train, center = TRUE, scale = TRUE)

media_tr = attr(data_train_z, 'scaled:center')
stdev_tr = attr(data_train_z, 'scaled:scale')

data_train_z = as.data.frame(data_train_z)

data_test = data_aux[test,]
rownames(data_test) <- NULL
data_test_z = as.data.frame(scale(data_test,  center = media_tr, scale = stdev_tr))

data_train_z$NIT = NIT_train
data_test_z$NIT = NIT_test

```

```{r}
r2_score <- function(x, y) summary(lm(y~x))$r.squared
adj_r2_score <- function(x, y) summary(lm(y~x))$adj.r.squared
```

## Modelo para los Costos

### Modelo Lineal General

```{r}
mod_lin = lm('Costo.de.ventas_dif~PIB+TRM+Desempleo+Inflacion+Tasa_Intervencion+Balance_CC+Balance_Fiscal', data = data_train_z)
```

```{r}
summary(mod_lin)
```
#### Desempeno del Modelo Entrenado

En el conjunto de entrenamiento:
```{r}
preds = predict(mod_lin)

plot(preds, data_train_z$Costo.de.ventas_dif, xlab = 'Valor predicho', ylab = 'Valor Real')
abline(a=0, b=1, lwd = 2, col = 'red')
```

Llevando los resultado previos a la escala original es claro como evaluación del modelo en el conjunto de entrenamiento se distribuye entre tres conjuntos de empresas, primero, aquellas con diferencia en sus costos de venta son ocupados en mayor proporción por valores negativos, otra srgunda donde permanecen en montos bajos y finalmente la tercera donde las diferencias en el costo son mayores que el resto. Si bien los resultados claramente no son satisfactorios nótese que el modelo no entrega valores absurdos, en tanto su valor máximo dado por \$2.699.228 se mantiene por debajo de \$36.609.681 que es el valor real, así mismo con su mínimo dado por -\$985489.8, el cual resulta por encima de su respectivo valor real de -\$17.903.909.

```{r}
plot(preds*stdev_tr['Costo.de.ventas_dif']+media_tr['Costo.de.ventas_dif'], 
     data_train_z$Costo.de.ventas_dif*stdev_tr['Costo.de.ventas_dif']+media_tr['Costo.de.ventas_dif'], xlab = 'Valor predicho', ylab = 'Valor Real')
abline(a=0, b=1, lwd = 2, col = 'red')
```
En el conjunto de Prueba
```{r}
preds_test = predict(mod_lin, newdata = data_test_z)
plot(preds_test, data_test_z$Costo.de.ventas_dif, xlab = 'Valor predicho', ylab = 'Valor Real')
abline(a=0, b=1, lwd = 2, col = 'red')
```

La situación vista en el conjunto de entrenamiento no se replica en el de testeo como se puede apreciar en la imagen, donde los valores predichos se encuentran en cuadrantes números considerablemente apartados de los reales; no obstante, las cifras aún son razonables dentro de los parámetros.

```{r}
plot(preds_test*stdev_tr['Costo.de.ventas_dif']+media_tr['Costo.de.ventas_dif'], 
     data_test_z$Costo.de.ventas_dif*stdev_tr['Costo.de.ventas_dif']+media_tr['Costo.de.ventas_dif'], xlab = 'Valor predicho', ylab = 'Valor Real')
abline(a=0, b=1, lwd = 2, col = 'red')
```


Medidas de (r2, r2_adj) para este modelo es:
```{r}
r2_model<-r2_score(preds_test, data_test_z$Costo.de.ventas_dif)
adj_r2_model<-adj_r2_score(preds_test, data_test_z$Costo.de.ventas_dif)
```

### Graficos de Evaluacion de modelos

```{r}
par(mfrow=c(3,2))
mod_plot = plot(mod_lin, which = c(1:6))
```

De los gráficos anteriores, en particular analizando el valor de la distancia de Cook para las observaciones, notamos que las observaciones 9, 12, 31, 58 son candidatas a ser registros atípicos en el conjunto de datos, por lo que entrenaremos un nuevo modelo eliminando estos registros. Notar que dos de esos outliers corresponden a la empresa con NIT 801002644 para los periodos del 2016 y del 2017, información que se contrasta con los outliers obtenidos en el boxplot, lo cual están incluidos tanto mirando la variable de costos como de gastos. los dos outliers restantes, corresponden a las empresas con NITs 860009694, 860050956 en los años 2016 y 2017 respectivamente. En particular estos registros no son encontrados como outliers en el boxplot, pero analizando en el 2018, ambas empresas si son identificadas como outliers debido a una diferencia significativa en los costos y gastos de venta respectivamente.

```{r}
### Vector para eliminar registros atipicos según la información obtenida por la distancia de cook
outliers = c(9, 12, 31, 58)
data_train_z_noOut = data_train_z[-outliers,]
```



```{r}
h_ii<-hatvalues(mod_lin)
plot(hatvalues(mod_lin),las=1,xlab="i",ylab="hii",main="Influencia (h_ii)",type="h")
```

### Inflacion de la varianza

```{r}
#vif(mod_lin)
```

## Entrenamiento del modelo sin Outliers

```{r}
mod_lin02 = lm('Costo.de.ventas_dif~PIB+TRM+Desempleo+Inflacion+Tasa_Intervencion+Balance_CC+Balance_Fiscal', data = data_train_z_noOut)
```

```{r}
summary(mod_lin02)
```


#### Desempeno del Modelo Entrenado sin Outliers

En el conjunto de entrenamiento:
```{r}
preds = predict(mod_lin02)

plot(preds, data_train_z_noOut$Costo.de.ventas_dif, xlab = 'Valor predicho', ylab = 'Valor Real')
abline(a=0, b=1, lwd = 2, col = 'red')
```

Retirando los outliers en el caso de entrenamiento afortunadamente la razonabilidad de los valores predichos se conserva, donde se puede observar que aunque se encuentran considerablemente desfasados de los reales se mantienen entre rangos aceptables.

```{r}
plot(preds*stdev_tr['Costo.de.ventas_dif']+media_tr['Costo.de.ventas_dif'], 
     data_train_z_noOut$Costo.de.ventas_dif*stdev_tr['Costo.de.ventas_dif']+media_tr['Costo.de.ventas_dif'], xlab = 'Valor predicho', ylab = 'Valor Real')
abline(a=0, b=1, lwd = 2, col = 'red')
```

En el conjunto de Prueba
```{r}
preds_test = predict(mod_lin02, newdata = data_test_z)
plot(preds_test, data_test_z$Costo.de.ventas_dif, xlab = 'Valor predicho', ylab = 'Valor Real')
abline(a=0, b=1, lwd = 2, col = 'red')
```

La tendencia a generar valores considerablemente menores a los reales por este modelo se replica con el conjunto de testeo, donde las diferencias de los costos de venta se alejan mucho más de los reales hasta a una escala de 10^5, lo que pone en duda la razonabilidad por este lado.

```{r}
plot(preds_test*stdev_tr['Costo.de.ventas_dif']+media_tr['Costo.de.ventas_dif'], 
     data_test_z$Costo.de.ventas_dif*stdev_tr['Costo.de.ventas_dif']+media_tr['Costo.de.ventas_dif'], xlab = 'Valor predicho', ylab = 'Valor Real')
abline(a=0, b=1, lwd = 2, col = 'red')
```

Medidas de (r2, r2_adj) para este modelo es:
```{r}
r2_model<-r2_score(preds_test, data_test_z$Costo.de.ventas_dif)
adj_r2_model<-adj_r2_score(preds_test, data_test_z$Costo.de.ventas_dif)
```


### Graficos de Evaluacion de modelos entrenando sin Outliers

```{r}
par(mfrow=c(3,2))
mod_plot = plot(mod_lin02, which = c(1:6))
```


### Modelo Lineal con Regularizacion

Vamos a encontrar el parametro de regulairzacion
```{r}
library(glmnet)

f1 = formula('Costo.de.ventas_dif~-1+PIB+TRM+Desempleo+Inflacion+Tasa_Intervencion+Balance_CC+Balance_Fiscal')


X = model.matrix(f1, data = as.data.frame(data_train_z))
Y = data_train_z$Costo.de.ventas

lambda_grid = 10^seq(1,-2,length.out = 100)
modelo_regularizacion = cv.glmnet(x = X, y = Y, lambda = lambda_grid)
```

```{r}
plot(modelo_regularizacion)
```

Entrenamos el modelo agregando el parametro de regularizacion, y asi ver relevancia de variables
```{r}
mod_lin_reg = glmnet(x = X, y = Y, lambda = modelo_regularizacion$lambda.min, alpha = 1, intercept = FALSE)
coef(mod_lin_reg)
```

## Modelos Lineales Generalizados (GLM)

Dentro de los modelos que fueron expuestos a lo largo del curso, se encuentra la familia de los modelos lineales generalizados, los cual nos permiten la creación de modelos teniendo en cuenta diferentes supuestos que se hacen sobre la variable respuesta que estamos considerando. En la elaboración de este trabajo, se está considerando realiza un modelo de predicción sobre la diferencia de los costos de ventas que tienen las empresas, por lo que el dominio de la variable son los números reales (ya que puede tomar valores continuos tanto positivos como negativos). Justo por la caracteristica de la variable respuesta que tenemos, no se considera pertinente realizar evaluacion de los modelos, esta conclusión está apoyada del análisis que se realiza de los diferentes modelos generalizados que podriamos considerar:

* Poisson: Para este modelo, esperamos que la variable respuesta tenga la forma de conteos, no negativa. Por lo que la diferencia de los costos de venta no aplica para este modelo.

* Logit: Este es un modelo logistico, el cual asume que la variable respuesta tendrá un comportamiento dentro del intervalo (0,1) el cual se utiliza para la predicción de la ocurrencia de un evento (ocurre o no ocurre), por lo que tampoco se ajusta para el modelamiento de la diferencia de costos de venta

* Gamma y Gaussiana inversa: De las distribuciones de probabilidad de la función gamma y gaussiana inversa, se sabe que los valores de la variable pueden ser continuos, por lo que nos llevaría a pensar de forma inicial que alguno de estos se puede considerar, pero en vista que tienen otra testricción, y es que los valores son continuos positivos, la variable de diferencia de costo de ventas tampoco se podría modelar con este tipo de modelos, ya que puede tomar valores negativos

* Gaussiana: Por la caracteristica de la distribución, sabemos que es posible modelar variables respuesta que su dominio sea los números reales, por lo que la variable de diferencia de costos de venta encaja en este tipo de modelo, ahora bien, esto es equivalente a considerar el modelo lineal general presentado anteriormente.

Por el análisis realizado, no se considera pertinente utilizar alguno de los otros modelos lineales generalizados para el modela miento de la variable diferencia de costos de venta


### Modelo de Efectos Mixtos

 

```{r}

#mod_me = lmer('Costo.de.ventas_dif~Gastos_de_ventas+(Gastos_de_ventas|NIT)', data = data_train_z)
mod_me = lmer('Costo.de.ventas_dif~PIB+(PIB|NIT)', data = data_train_z)
```

 

```{r}
par(mfrow=c(3,2))
plot(mod_me, which = c(1:6))
```

 

```{r}
preds = predict(mod_me)
plot(preds,data_train_z$Costo.de.ventas_dif)
abline(a=0, b=1, lwd = 2, col = 'red')
```

Considerando esta clase de modelos se puede observar la captura de la tendencia generada por los montos de diferencia de costos de ventas de acuerdo a los tamaños de las empresas consideradas, donde para algunas pocas los valores predichos naturalmente exceden los del resto, tanto en el sentido positivo como en el negativo, lo cual es esperado. Este nuevo ajuste, influenciado por el PIB, es el más natural en el mercado, dada la correlación entre éste y la medida de salida.

```{r}
plot(preds*stdev_tr['Costo.de.ventas_dif']+media_tr['Costo.de.ventas_dif'], 
     data_train_z$Costo.de.ventas_dif*stdev_tr['Costo.de.ventas_dif']+media_tr['Costo.de.ventas_dif'])
abline(a=0, b=1, lwd = 2, col = 'red')
```

```{r}
preds = predict(mod_me, newdata = data_test_z,allow.new.levels=TRUE)
plot(preds,data_test_z$Costo.de.ventas_dif)
abline(a=0, b=1, lwd = 2, col = 'red')
```

Desafortunadamente en el caso de prueba no se logra distinguir la tendencia natural en el comportamiento de la diferencia de los costos de venta y la escala se encuentra muy distante entre los valores predichos y los reales, como se espera desde el gráfico anterior. En esta evaluación los valores predichos se ponderan para generar una tendencia casi constante y la razonabilidad una vez más se pone en duda, aunque no por completo, dado que éstos valores efectivamente pueden ser alcanzados con condiciones ligeramente diferentes.

```{r}
plot(preds*stdev_tr['Costo.de.ventas_dif']+media_tr['Costo.de.ventas_dif'], 
     data_test_z$Costo.de.ventas_dif*stdev_tr['Costo.de.ventas_dif']+media_tr['Costo.de.ventas_dif'])
abline(a=0, b=1, lwd = 2, col = 'red')
```
 

```{r}
## Generalized linear model Lasso
glm_obj <- glmmLasso(Costo.de.ventas_dif~TRM+PIB+Desempleo+Inflacion+Tasa_Intervencion+Balance_CC+Balance_Fiscal, rnd = list(NIT=~1+PIB+Balance_CC), data = data_train_z, lambda=10, family = gaussian(link ="identity"))
summary(glm_obj)
```

 

```{r}
preds = predict(glm_obj, data = data_train_z)
plot(preds,data_train_z$Costo.de.ventas_dif)
abline(a=0, b=1, lwd = 2, col = 'red')
```

Bajo esta aplicación del modelo Lasso es claro como ya se presenta una mejor distribución de los valores predichos contra los reales y éste es un comportamiento más natural y razonable en la industria, donde si bien hay un par que se alejan del común respecto a las diferencias en los costos de venta, el resto dentro de sus segmentos también puede tener distribuciones similares teniendo en cuenta sus montos.

```{r}
plot(preds*stdev_tr['Costo.de.ventas_dif']+media_tr['Costo.de.ventas_dif'], 
     data_train_z$Costo.de.ventas_dif*stdev_tr['Costo.de.ventas_dif']+media_tr['Costo.de.ventas_dif'])
abline(a=0, b=1, lwd = 2, col = 'red')
```

```{r}
r2_model_train<-r2_score(preds, data_train_z$Costo.de.ventas_dif)
adj_r2_model_train<-adj_r2_score(preds, data_train_z$Costo.de.ventas_dif)
mse_train = mean((data_train_z$Costo.de.ventas_dif - preds)^2)

print(r2_model_train)
print(adj_r2_model_train)
print(mse_train)
```


```{r}
preds = predict(glm_obj, newdata = data_test_z)
plot(preds,data_test_z$Costo.de.ventas_dif)
abline(a=0, b=1, lwd = 2, col = 'red')
```

Como se presenta a continuación en esta oportunidad se captura algo de la relación positiva entre los valores predichos y los reales. Exceptuando los valores atipicos la razonabilidad se pone en duda debido al sentido de los signos y la propensión de éstos modelos a entregar resultados en escalas menores a las esperadas.

```{r}
plot(preds*stdev_tr['Costo.de.ventas_dif']+media_tr['Costo.de.ventas_dif'], 
     data_test_z$Costo.de.ventas_dif*stdev_tr['Costo.de.ventas_dif']+media_tr['Costo.de.ventas_dif'])
abline(a=0, b=1, lwd = 2, col = 'red')
``` 


```{r}
infl <- influence(mod_me, obs = TRUE)
cooks.distance(infl)
plot(infl, which = "cook")

 

```

 

```{r}
r2_model_test<-r2_score(preds, data_test_z$Costo.de.ventas_dif)
adj_r2_model_test<-adj_r2_score(preds, data_test_z$Costo.de.ventas_dif)
mse_test = mean((data_test_z$Costo.de.ventas_dif - preds)^2)

print(r2_model_test)
print(adj_r2_model_test)
print(mse_test)
```

 


```{r}
plot(all_data$Year, all_data$Costo.de.ventas, col=all_data$NIT, xlab = "AÃ±o", ylab = "Valor del Costo de Venta por Empresa")
```

 

 

 

 

```{r}
## Generalized linear model Lasso quitando empresa outlier
data_train_z_sinoutl = data_train_z[-c(12, 34, 56), ]
glm_obj_s <- glmmLasso(Costo.de.ventas_dif~TRM+PIB+Balance_CC+Desempleo+Balance_Fiscal, rnd = list(NIT=~1+PIB), data = data_train_z_sinoutl, lambda=5, family = gaussian(link ="identity"))
summary(glm_obj_s)
```

 

```{r}
preds = predict(glm_obj_s, data = data_train_z_sinoutl)
plot(preds,data_train_z_sinoutl$Costo.de.ventas_dif)
abline(a=0, b=1, lwd = 2, col = 'red')
```

Aplicando la remoción de outliers la distribución hacia el centro de los datos se extiende más y esto es deseado, y la escala no se ve demasiado afectada por la corrección. En términos de mercado esta clase de resultados es la más natural y razonable entre todas, donde es claro como los indicadores macro-economicos pueden afectar de manera diferente a cada componente que representa la industria.

```{r}
plot(preds*stdev_tr['Costo.de.ventas_dif']+media_tr['Costo.de.ventas_dif'], 
     data_train_z_sinoutl$Costo.de.ventas_dif*stdev_tr['Costo.de.ventas_dif']+media_tr['Costo.de.ventas_dif'])
abline(a=0, b=1, lwd = 2, col = 'red')
```

```{r}
r2_model_train_sinoutl<-r2_score(preds, data_train_z_sinoutl$Costo.de.ventas_dif)
adj_r2_model_train_sinoutl<-adj_r2_score(preds, data_train_z_sinoutl$Costo.de.ventas_dif)
mse_sinoutl = mean((data_train_z_sinoutl$Costo.de.ventas_dif - preds)^2)

print(r2_model_train_sinoutl)
print(adj_r2_model_train_sinoutl)
print(mse_sinoutl)
```

 

```{r}
preds = predict(glm_obj_s, newdata = data_test_z)
plot(preds,data_test_z$Costo.de.ventas_dif)
abline(a=0, b=1, lwd = 2, col = 'red')
```

Probando con el conjunto de testeo puede verse en comparación al resultado en test del modelo anterior que la distorsión se evidencia hacia los valores mayores en el conjunto predicho y el sentido de los signos, lo que le reduce razonabilidad. Sobre el efecto de escala éste se esperaba dado el resultado en el set de entrenamiento.

```{r}
plot(preds*stdev_tr['Costo.de.ventas_dif']+media_tr['Costo.de.ventas_dif'], 
     data_test_z$Costo.de.ventas_dif*stdev_tr['Costo.de.ventas_dif']+media_tr['Costo.de.ventas_dif'])
abline(a=0, b=1, lwd = 2, col = 'red')
```


```{r}
r2_model_test_sinoutl<-r2_score(preds, data_test_z$Costo.de.ventas_dif)
adj_r2_model_test_sinoutl<-adj_r2_score(preds, data_test_z$Costo.de.ventas_dif)
mse_sinoutl_test = mean((data_test_z$Costo.de.ventas_dif - preds)^2)

print(r2_model_test_sinoutl)
print(adj_r2_model_test_sinoutl)
print(mse_sinoutl_test)
```

 

```{r}
## Trasnformacion de variables (productos y divisiones)
vars = c("TRM","PIB","Desempleo","Inflacion","Tasa_Intervencion","Balance_CC","Balance_Fiscal")
df = data_train_z[vars]
# x^2
df_p <- df^2
vector = c()
for (i in colnames(df)) vector <- c(vector, paste(i,'_p_',i, sep  = ''))
colnames(df_p) <-  vector
# xi*xj
df_s <- do.call(cbind,combn(colnames(df), 2,
               FUN= function(x) list(df[x[1]]*df[x[2]])))
colnames(df_s) <-  combn(colnames(df), 2,
                 FUN = paste, collapse="_p_")
# xi/xj
df_t <- do.call(cbind,combn(colnames(df), 2,
               FUN= function(x) list(df[x[1]]/df[x[2]])))
colnames(df_t) <-  combn(colnames(df), 2,
                 FUN = paste, collapse="_d_")
df_trans=cbind(data_train_z,df_p,df_s,df_t)
```

 


```{r}
## Generalized linear model Lasso con todas las transformaciones
glm_obj <- glmmLasso(Costo.de.ventas_dif~TRM+PIB+Desempleo+Inflacion+Tasa_Intervencion+Balance_CC+Balance_Fiscal+TRM_p_TRM+PIB_p_PIB+Desempleo_p_Desempleo+Inflacion_p_Inflacion+Tasa_Intervencion_p_Tasa_Intervencion+Balance_CC_p_Balance_CC+Balance_Fiscal_p_Balance_Fiscal+TRM_p_PIB+TRM_p_Desempleo+TRM_p_Inflacion+TRM_p_Tasa_Intervencion+TRM_p_Balance_CC+TRM_p_Balance_Fiscal+PIB_p_Desempleo+PIB_p_Inflacion+PIB_p_Tasa_Intervencion+PIB_p_Balance_CC+PIB_p_Balance_Fiscal+Desempleo_p_Inflacion+Desempleo_p_Tasa_Intervencion+Desempleo_p_Balance_CC+Desempleo_p_Balance_Fiscal+Inflacion_p_Tasa_Intervencion+Inflacion_p_Balance_CC+Inflacion_p_Balance_Fiscal+Tasa_Intervencion_p_Balance_CC+Tasa_Intervencion_p_Balance_Fiscal+Balance_CC_p_Balance_Fiscal+TRM_d_PIB+TRM_d_Desempleo+TRM_d_Inflacion+TRM_d_Tasa_Intervencion+TRM_d_Balance_CC+TRM_d_Balance_Fiscal+PIB_d_Desempleo+PIB_d_Inflacion+PIB_d_Tasa_Intervencion+PIB_d_Balance_CC+PIB_d_Balance_Fiscal+Desempleo_d_Inflacion+Desempleo_d_Tasa_Intervencion+Desempleo_d_Balance_CC+Desempleo_d_Balance_Fiscal+Inflacion_d_Tasa_Intervencion+Inflacion_d_Balance_CC+Inflacion_d_Balance_Fiscal+Tasa_Intervencion_d_Balance_CC+Tasa_Intervencion_d_Balance_Fiscal+Balance_CC_d_Balance_Fiscal, rnd = list(NIT=~1+PIB+Balance_CC), data = df_trans, lambda=15, family = gaussian(link ="identity"))
summary(glm_obj)
### Para que converja, toca poner un lamba alto. Esto conlleva a que todas las betas sean 0
### Un lambda menor lleva a que la matriz no sea invertible
```

 

### Lambda bajo
```{r}
## Generalized linear model Lasso con todas las transformaciones de Balance_CC
glm_obj_tr <- glmmLasso(Costo.de.ventas_dif~Balance_CC+PIB+Balance_Fiscal, rnd = list(NIT=~1+PIB+Balance_CC), data = df_trans, lambda=1, family = gaussian(link ="identity"))
summary(glm_obj_tr)

```
```{r}
preds = predict(glm_obj_tr, data = data_train_z)
plot(preds,data_train_z$Costo.de.ventas_dif)
abline(a=0, b=1, lwd = 2, col = 'red')
```
```{r}
r2_model_train_new<-r2_score(preds, data_train_z$Costo.de.ventas_dif)
adj_r2_model_train_new<-adj_r2_score(preds, data_train_z$Costo.de.ventas_dif)
mse_new = mean((data_train_z$Costo.de.ventas_dif - preds)^2)

print(r2_model_train_new)
print(adj_r2_model_train_new)
print(mse_new)
```

```{r}
preds = predict(glm_obj_tr, newdata = data_test_z)
plot(preds,data_test_z$Costo.de.ventas_dif)
abline(a=0, b=1, lwd = 2, col = 'red')
```
```{r}
r2_model_test_new<-r2_score(preds, data_test_z$Costo.de.ventas_dif)
adj_r2_model_test_new<-adj_r2_score(preds, data_test_z$Costo.de.ventas_dif)
mse_new_test = mean((data_test_z$Costo.de.ventas_dif - preds)^2)

print(r2_model_test_new)
print(adj_r2_model_test_new)
print(mse_new_test)
```

### Lambda alto
```{r}
## Generalized linear model Lasso con todas las transformaciones de Balance_CC
glm_obj_tr <- glmmLasso(Costo.de.ventas_dif~Balance_CC+PIB+Balance_Fiscal, rnd = list(NIT=~1+PIB+Balance_CC), data = df_trans, lambda=12, family = gaussian(link ="identity"))
summary(glm_obj_tr)

```
```{r}
preds = predict(glm_obj_tr, data = data_train_z)
plot(preds,data_train_z$Costo.de.ventas_dif)
abline(a=0, b=1, lwd = 2, col = 'red')
```
```{r}
r2_model_train_new<-r2_score(preds, data_train_z$Costo.de.ventas_dif)
adj_r2_model_train_new<-adj_r2_score(preds, data_train_z$Costo.de.ventas_dif)
mse_new = mean((data_train_z$Costo.de.ventas_dif - preds)^2)

print(r2_model_train_new)
print(adj_r2_model_train_new)
print(mse_new)
``` 

```{r}
preds = predict(glm_obj_tr, newdata = data_test_z)
plot(preds,data_test_z$Costo.de.ventas_dif)
abline(a=0, b=1, lwd = 2, col = 'red')
```
```{r}
r2_model_test_new<-r2_score(preds, data_test_z$Costo.de.ventas_dif)
adj_r2_model_test_new<-adj_r2_score(preds, data_test_z$Costo.de.ventas_dif)
mse_new_test = mean((data_test_z$Costo.de.ventas_dif - preds)^2)

print(r2_model_test_new)
print(adj_r2_model_test_new)
print(mse_new_test)
```