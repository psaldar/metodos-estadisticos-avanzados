---
title: "Trabajo Final - Métodos Estadísticos Avanzados en Ciencia de los Datos"
author: "Pablo Saldarriaga-Aristizabal, Nicolás Prieto-Escobar, Obed Rios-Ruiz"
date: "Semestre 2020-1"
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
library(readxl)
library(ggplot2)
library(kableExtra)
library(matrixStats)
library(Hmisc)
library(pastecs)
library(corrplot)
library(mvtnorm)
library(ggplot2)
library(dplyr)
library(lme4)
```


## Introduccion

La intro

## Clasificación Industrial Seleccionada

La cementera

## Consolidación de Información

```{r}
all_data = read.csv("PreparacionDatos/Data/consolidado_info.csv", encoding="UTF-8")
data = all_data[,-c(1,2)]
```


## Transformación  de Variables y Análisis Descriptivo


Damos una visualizacion inicial al conjunto de datos con el que se va a trabajar:

```{r}
head(data)
```

En la siguiente tabla, vemos información descriptiva de las variables que se considerarán en la etapa de modelamiento del trabajo, vemos así que contamos con un total de 11 variables, cada una con magnitudes diferentes. Vemos que algunos indicadores tienen valores entre 0 y 1 tal como lo es el desempleo, mientras que otras variables representan dinero, tal como la trm, el monto de gastos y ventas. Así, tenemos una idea inicial de las características del conjunto de datos, por lo que se aplicarán lo métodos correspondientes cuando sea necesario, si lo que se realizará es sensible a la escala de los datos.

```{r}
(summary_df <- stat.desc(data))
```
Además de la información descriptiva presentados en la tabla anterior, podemos ver para cada una de las variables, su distribución de forma visual con la ayuda de la creación de histogramas de frecuencia.

```{r}
hist(data)
```


Vamos a obtener la informacion relacionada a las medidas de centralidad y dispersion del conjunto de datos. Inicialmente, presentamos información del vector de medias y medianas que describen la centralidad del conjutno de datos. Posteriormente, consideramos las matrices de Covarianza y Correlación para tener una intuición de la variabilidad de la información que consideramos.

#### Vector de Medias
```{r}
(mean_data = colMeans(data))
```

### Vector de Medianas
```{r}
median_data = colMedians(as.matrix(data))
names(median_data) = names(data)
median_data
```

### Boxplot

```{r}
par(mfrow=c(1,2))
bxplot_costos = boxplot(Costo_de_ventas~YEAR, data = all_data)
bxplot_gastos = boxplot(Gastos_de_ventas~YEAR, data = all_data)
```

```{r}
### Outliers para costos
all_data[(all_data$Costo_de_ventas %in% bxplot_costos$out),]$NIT
```

```{r}
### Outliers para gastos
all_data[(all_data$Gastos_de_ventas %in% bxplot_gastos$out),]$NIT
```

Al observar la distribución del comportamiento de las variables de ventas y gastos para los 3 años en consideración, podemos ver que no hay mucha variación entre el comportamiento de estas a lo largo del tiempo, vemos que en particular, tanto el monto de costo y gasto promedio (mediana) es constante para los 3 años, aunque se nota un aumento en los costos en el año 2018 para el caso de algunas empresas. Ademas, vemos para que caso de los Costos, las mismas 2 empresas (relacionadas a los NITs 860009694 y 900378893) fueron las que presentaron un maypr valor de costos en los 3 periodos, por lo que el boxplot los considera registros outliers. Mirando la distribución de los gatos, notamos que una empresa tuvo los gastos mas altos en los 3 periodos (relacionadas al NIT 801002644) pero adicional, en el último año, la empresa con el NIT 800015615 tuvo un aumento en sus gastos, por lo que es considerado también como un outlier por el boxplot.



#### Matriz de Covarianzas
```{r}
(cov_data = cov(data))
```

#### Matriz de Correlación
```{r}
(cor_data = cor(data))
```

```{r}
corrplot(cor_data, method="circle")
```

Dado que en este trabajo se pretende realizar la modelación de las variables de costo y gasto de ventas, la matriz de correlación es un buen indicador para observar relaciones lineales existentes en las variables. En particular, vemos para el caso de la información de gastos, una "fuerte" correlación de las variables de costo, diferencia de costos y diferencia de ventas. Para este caso, es natural encontrar una correlacion positiva con dichas variables, pues es claro que costos y gastos están asociados entre sí. Igualmente, la variable de diferencia de gastos, fue calculada con la variable gastos, por lo tanto tiene sentido encontrar esta correlación. Por otro lado, tanto para la variable de ventas como gastos, no se ven correlaciones fuertes en relación a las variables macro-económicas, lo que nos indica que no existe una relación lineal entre esta variable y las demás. Por lo que una buena alternativa en este trabajo, será considerar transformaciones no lineales de las variables para encontrar una dependencia con la información de los costos de venta.

## Visualizacion de la distribucion de los datos


```{r}
panel.cor <- function(x, y, digits = 2, prefix = "", cex.cor, ...)
{
    usr <- par("usr"); on.exit(par(usr))
    par(usr = c(0, 1, 0, 1))
    r <- abs(cor(x, y))
    txt <- format(c(r, 0.123456789), digits = digits)[1]
    txt <- paste0(prefix, txt)
    if(missing(cex.cor)) cex.cor <- 0.8/strwidth(txt)
    text(0.5, 0.5, txt, cex = cex.cor * r)
}

panel.hist <- function(x, ...)
{
    usr <- par("usr"); on.exit(par(usr))
    par(usr = c(usr[1:2], 0, 1.5) )
    h <- hist(x, plot = FALSE)
    breaks <- h$breaks; nB <- length(breaks)
    y <- h$counts; y <- y/max(y)
    rect(breaks[-nB], 0, breaks[-1], y, col = "black", ...)
}
```

```{r}
pairs(data,diag.panel = panel.hist, lower.panel = panel.cor)
```

### Visualizacion de los datos segun curvas de normalidad

```{r}
### Funcion para encontrar los contornos
c_alpha = function(alpha, sigma, p){
  res = (2*pi)^(-p/2)*(det(sigma))^(-1/2)*exp(-1/2*qchisq(1-alpha, df = p))
  
  return(res)
}

grafica = function(data, name1, name2){

  data_aux = data[c(name1,name2)]
  names(data_aux) = c("y1","y2")
  
  cov_data = cov(data_aux)
  mean_data = mean=colMeans(data_aux)
  
  min_value1 = min(data[name1])
  max_value1 = max(data[name1])
  
  min_value2 = min(data[name2])
  max_value2 = max(data[name2])
  
  n = 100
  
  y1 = seq(min_value1, max_value1, length.out = n)
  y2 = seq(min_value2, max_value2, length.out = n)
  
  grid = expand.grid(y1,y2)
  grid$Z<-apply(grid,1,dmvnorm,mean = mean_data,sigma=cov_data)
  Z<-matrix(grid$Z,nrow=n,ncol=n)
  
  contornos = sapply(c(0.01, 0.05, 0.1), c_alpha, sigma = cov_data, 2)
  
  contour(y1,y2,Z,levels=contornos,labels=c("99%","95%","90%"),
          las=1)
  points(data_aux$y1,data_aux$y2)
  grid()  
  title(main = "Contornos de distribucion normal", xlab = name1, ylab = name2)
}
```

```{r}
p1 = grafica(data, "trm", "pib")
```

```{r}
p2 = grafica(data, "Costo_de_ventas" , "Costo_de_ventas_dif")
```

```{r}
p3 = grafica(data, "Costo_de_ventas" , "Gastos_de_ventas")
```

### Creacion de modelos

```{r}
data_aux = select(all_data,select = -starts_with('NIT'))

data_train = subset(data_aux, subset = YEAR<2018)
data_train_z = scale(data_train, center = TRUE, scale = TRUE)

media_tr = attr(data_train_z, 'scaled:center')
stdev_tr = attr(data_train_z, 'scaled:scale')

data_train_z = as.data.frame(data_train_z)

data_test = subset(data_aux, subset = YEAR>=2018)
data_test_z = as.data.frame(scale(data_test,  center = media_tr, scale = stdev_tr))
```

## Modelo para los Costos

### Modelo Lineal General

```{r}
mod_lin = lm('Costo_de_ventas~pib+trm', data = data_train_z)
```

```{r}
summary(mod_lin)
```
#### Desempeno del Modelo Entrenado

En el conjunto de entrenamiento:
```{r}
preds = predict(mod_lin)

plot(preds, data_train_z$Costo_de_ventas, xlab = 'Valor predicho', ylab = 'Valor Real')
abline(a=0, b=1, lwd = 2, col = 'red')
```

En el conjunto de Prueba
```{r}
preds_test = predict(mod_lin, newdata = data_test_z)
plot(preds_test, data_test_z$Costo_de_ventas, xlab = 'Valor predicho', ylab = 'Valor Real')
abline(a=0, b=1, lwd = 2, col = 'red')
```

### Graficos de Evaluacion de modelos

```{r}
par(mfrow=c(2,2))
plot(mod_lin, which = c(1:4))
```


### Modelo Lineal con Regularizacion

Vamos a encontrar el parametri de regulairzacion
```{r}
library(glmnet)

f1 = formula('Costo_de_ventas~balance_fiscal+desempleo+inflacion+pib+tasa_intervencion+trm')

X = model.matrix(f1, data = as.data.frame(data_train_z))
Y = data_train_z$Costo_de_ventas

lambda_grid = 10^seq(10,-2,length.out = 100)
modelo_regularizacion = cv.glmnet(x = X, y = Y, lambda = lambda_grid)
```

```{r}
plot(modelo_regularizacion)
```

Entrenamos el modelo agregando el parametro de regularizacion, y asi ver relevancia de variables
```{r}
mod_lin_reg = glmnet(x = X, y = Y, lambda = modelo_regularizacion$lambda.min, alpha = 1, intercept = FALSE)
coef(mod_lin_reg)
```


### Modelo de Efectos Mixtos

```{r}
### Esto aun no funciona
#mod_me = lmer('Costo_de_ventas~balance_fiscal+(Costo_de_ventas|balance_fiscal)', data = data_train_z)
```



```{r}
plot(all_data$YEAR, all_data$Costo_de_ventas, col=all_data$NIT, xlab = "Año", ylab = "Valor del Costo de Venta por Empresa")
```

 






















